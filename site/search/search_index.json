{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ProbeTruth Documentation","text":""},{"location":"#overview","title":"Overview","text":"<p>ProbeTruth is an advanced AI-driven platform designed to detect deepfakes and combat digital identity fraud. Our flagship solution, DeepTect, leverages NeuroSymbolic AI and multimodal techniques to ensure transparency and accuracy in verifying digital content.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Comprehensive Detection Capabilities: Identifies basic, partial, shallow, and complex deepfakes across various media formats.</li> <li>Explainable Reporting: Generates detailed, transparent, and defensible reports that are easily understood.</li> <li>Security-First Architecture: Built with robust security measures to guard against manipulation and ensure data integrity.</li> <li>User-Centric Design: Offers intuitive interfaces and workflows tailored for legal professionals, organizations, and individuals.</li> <li>Collaborative Integration: Works seamlessly with governments, businesses, and research institutions to set global standards in digital content verification.</li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<ul> <li>Legal and Forensic Analysis: Assisting legal professionals in verifying the authenticity of digital evidence.</li> <li>Media and Journalism: Helping journalists and media outlets detect and prevent the spread of manipulated content.</li> <li>Corporate Security: Enabling businesses to protect against digital identity fraud and misinformation.</li> <li>Public Sector Applications: Supporting government agencies in safeguarding public information and communications.</li> </ul>"},{"location":"#accessing-probetruth","title":"Accessing ProbeTruth","text":"<p>To learn more about our services or to schedule a demo, visit our About Us page or contact us at demo@probetruth.ai.</p>"},{"location":"contact/","title":"Contact Us","text":"<p>We\u2019d love to hear from you! Whether you\u2019re interested in our services, have questions about our platform, or want to collaborate \u2014 feel free to get in touch.</p>"},{"location":"contact/#general-inquiries","title":"General Inquiries","text":"<p>For general questions, partnership opportunities, or media inquiries, reach out to:</p> <p>Email: contact@probetruth.ai</p>"},{"location":"contact/#research-collaborations","title":"Research Collaborations","text":"<p>If you're from academia or a research institution and are interested in working together on deepfake detection, AI security, or related topics:</p> <p>Email: research@probetruth.ai</p>"},{"location":"contact/#business-enterprise-solutions","title":"Business &amp; Enterprise Solutions","text":"<p>For enterprise support, custom integrations, or bulk analysis options, please contact:</p> <p>Email: business@probetruth.ai</p>"},{"location":"contact/#office-location","title":"Office Location","text":"<p>ProbTruth Inc. Tower Plaza 555 E William St, Ann Arbor, MI 48104</p>"},{"location":"contact/#support-hours","title":"Support Hours","text":"<p>Monday to Friday: 9:00 AM \u2013 5:00 PM (EST) Saturday &amp; Sunday: Closed</p> <p>Thank you for reaching out to us. We'll respond to your message as soon as possible!</p>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":"<p>This page will be updated soon with answers to the most common questions about using the ProbeTruth API and platform.</p> <p>Stay tuned!</p>"},{"location":"generate_report/","title":"Generate Forensic Report","text":"<p>After completing the media inspection, you can generate a comprehensive PDF report summarizing the results of the deepfake detection process. This report can be downloaded and printed for legal, forensic, or internal documentation purposes.</p>"},{"location":"generate_report/#how-it-works","title":"How It Works","text":"<p>Once the media has been analyzed and predictions are available, clicking the \"Generate Report\" button will:</p> <ol> <li>Compile all analysis results.</li> <li>Structure the content into a formal forensic report.</li> <li>Provide a downloadable PDF or JSON file with optional print support.</li> </ol>"},{"location":"generate_report/#report-contents","title":"Report Contents","text":"<p>The generated report includes the following sections:</p>"},{"location":"generate_report/#1-general-information","title":"1. General Information","text":"<ul> <li>Media ID</li> <li>Upload timestamp</li> <li>Media type (video, audio, image)</li> <li>File name and format</li> <li>User or API key identifier (if applicable)</li> </ul>"},{"location":"generate_report/#2-metadata-extraction","title":"2. Metadata Extraction","text":"<ul> <li>Resolution / duration / size</li> <li>File properties and encoding format</li> <li>Hash or unique media signature</li> </ul>"},{"location":"generate_report/#3-model-analysis-summary","title":"3. Model Analysis Summary","text":"<ul> <li>List of models used for analysis</li> <li>Individual predictions with confidence scores</li> <li>Verdicts (e.g., Authentic / Deepfake)</li> </ul>"},{"location":"generate_report/#4-explanation-evidence","title":"4. Explanation &amp;  Evidence","text":"<ul> <li>Key frame thumbnails (for video/image)</li> <li>Audio waveform or spectrogram (for audio)</li> <li>Highlighted anomalies (if supported)</li> </ul>"},{"location":"generate_report/#5-final-verdict","title":"5. Final Verdict","text":"<ul> <li>Overall decision (e.g., Deepfake Detected)</li> <li>Confidence level</li> <li>Timestamp of decision</li> </ul> <p>The report is digitally signed and watermarked with the ProbeTruth seal to ensure authenticity.</p>"},{"location":"generate_report/#download-print","title":"Download &amp; Print","text":"<ul> <li>The generated report is available in PDF or JSON format.</li> <li>Users can download or print directly from the browser.</li> <li>Reports can also be accessed later via the media history panel (if enabled).</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to ProbeTruth \u2014 your trusted solution for detecting deepfakes and protecting digital identity.</p> <p>This guide walks you through the basic steps to start using the ProbeTruth platform, whether you\u2019re a legal investigator, journalist, or individual user seeking truth in digital content.</p>"},{"location":"getting-started/#who-can-use-probetruth","title":"Who Can Use ProbeTruth?","text":"<p>ProbeTruth is designed for:</p> <ul> <li>General users needing one-time verification of media.</li> <li>Legal professionals and investigators handling digital evidence.</li> <li>Organizations looking for automated, scalable deepfake detection via dashboards or APIs.</li> </ul>"},{"location":"getting-started/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"getting-started/#1-create-an-account","title":"1. Create an Account","text":"<p>Choose one of the following:</p> <ul> <li>Paid Subscription: Unlock full access with a personalized dashboard and file history.</li> <li>One-Time Use: Use our limited, quick-access upload service \u2014 no account needed.</li> </ul> <p>\ud83d\udca1 API access requires a subscription and an API key.</p>"},{"location":"getting-started/#2-upload-your-media","title":"2. Upload Your Media","text":"<ul> <li>Log in to your dashboard or use the public upload page.</li> <li>Select your media file(s) for inspection \u2014 video, audio, or image formats are supported.</li> </ul>"},{"location":"getting-started/#3-wait-for-analysis","title":"3. Wait for Analysis","text":"<ul> <li>Our AI pipeline processes your media using multiple deepfake detection models.</li> <li>Most results are returned within a few minutes.</li> <li>Progress and status updates are visible in the dashboard (for subscribers).</li> </ul>"},{"location":"getting-started/#4-download-your-report","title":"4. Download Your Report","text":"<ul> <li>Once complete, a detailed forensic report is generated.</li> <li>Reports include authenticity verdicts, visual evidence, metadata, and model decisions.</li> <li>Download or share securely via your dashboard.</li> </ul>"},{"location":"getting-started/#api-access-for-developers-and-b2b-clients","title":"API Access (For Developers and B2B Clients)","text":"<ul> <li>Subscribers with a valid API key can use our RESTful API to automate uploads and receive results.</li> <li>API documentation is available here.</li> </ul>"},{"location":"getting-started/#business-subscription-options","title":"Business &amp; Subscription Options","text":"<p>ProbeTruth offers tailored solutions for businesses: - B2B SaaS Access: Scalable platform access with usage-based billing. - White Labeling: Customize our platform under your brand with full API and dashboard integration.</p> <p>Contact demo@probetruth.ai to discuss your business needs.</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the API Reference</li> <li>Learn about our Detection Models</li> <li>Review our Security Practices</li> </ul> <p>Need help? Contact us anytime at support@probetruth.ai</p>"},{"location":"inspect_media/","title":"Media Inspection","text":"<p>Once a media file is successfully uploaded using the <code>POST /v1/media</code> endpoint, you can initiate deepfake analysis through the \"Inspect Media\" action in the ProbeTruth interface.</p> <p>This process automatically triggers backend analysis using multiple AI models, depending on the type of uploaded media (video, audio, or image). No additional API call or input parameters are required at this step.</p>"},{"location":"inspect_media/#workflow","title":"Workflow","text":"<ol> <li> <p>Upload Media    Upload a video, audio, or image file using the <code>/v1/media</code> endpoint.</p> </li> <li> <p>Inspect Media    After upload, click the \"Inspect Media\" button in the ProbeTruth dashboard. This triggers backend analysis.</p> </li> <li> <p>Model Processing    Based on the type of media:</p> </li> <li>Visual models are run for images/videos.</li> <li>Audio models for audio clips.</li> <li>Audiovisual models for eligible media types.</li> </ol> <p>Each model processes the file in parallel or sequentially, depending on configuration.</p> <ol> <li>Live Feedback </li> <li>During analysis, a status bar or loading icon is shown.</li> <li>Once complete, the frontend displays predictions and confidence scores.</li> </ol>"},{"location":"inspect_media/#backend-behavior","title":"Backend Behavior","text":"<ul> <li>The system automatically selects the appropriate models based on the uploaded media type.</li> <li>No additional input parameters are required.</li> <li>The analysis status is updated in real time.</li> </ul>"},{"location":"inspect_media/#example-response-gui-display","title":"Example Response (GUI Display)","text":"Model Confidence Verdict VisualNet V2 93.2% Deepfake AudioAnalyzer X 98.7% Authentic Fusion AI 95.1% Deepfake <p>Final Decision: Deepfake Detected</p>"},{"location":"inspect_media/#next-step-generate-report","title":"Next Step: Generate Report","text":"<p>Once the inspection is complete, users can click on the \"Generate Report\" button to receive a downloadable PDF forensic report containing:</p> <ul> <li>Metadata</li> <li>Model decisions</li> <li>Confidence scores</li> <li>Visual evidence (if available)</li> </ul>"},{"location":"models/","title":"Detection Models","text":"<p>ProbeTruth leverages a suite of advanced AI models to detect deepfakes across visual, audio, and audiovisual domains. Each model targets specific forgery cues using state-of-the-art machine learning techniques.</p>"},{"location":"models/#audiovisual-model","title":"Audiovisual Model","text":""},{"location":"models/#darl-v10","title":"DARL (v1.0)","text":"<ul> <li>Type: Audiovisual</li> <li>Focus: Speech-Lips Synchronization</li> <li>Description: DARL analyzes the temporal alignment between speech audio and corresponding lip movements in video. It flags inconsistencies that are indicative of synthetic tampering or lip-sync manipulation.</li> </ul>"},{"location":"models/#visual-models","title":"Visual Models","text":""},{"location":"models/#dbag-net-v10","title":"DBaG-Net (v1.0)","text":"<ul> <li>Type: Visual</li> <li>Focus: Facial Geometry</li> <li>Description: DBaG-Net detects abnormalities in facial proportions, landmarks, and geometric consistency that are often introduced by deepfake generation processes.</li> </ul>"},{"location":"models/#atten-vit-v10","title":"Atten-ViT (v1.0)","text":"<ul> <li>Type: Visual</li> <li>Focus: Spatial Artifacts</li> <li>Description: Based on Vision Transformers, Atten-ViT captures subtle pixel-level and regional inconsistencies, such as unnatural textures or blending errors in forged images or video frames.</li> </ul>"},{"location":"models/#audio-models","title":"Audio Models","text":""},{"location":"models/#audio-rrl-v10","title":"Audio-RRL (v1.0)","text":"<ul> <li>Type: Aural</li> <li>Focus: Spectro-temporal Artifacts</li> <li>Description: Audio-RRL identifies temporal inconsistencies and unnatural frequency patterns in audio, which may result from voice synthesis or manipulation techniques.</li> </ul>"},{"location":"models/#psa-net-v10","title":"PSA-Net (v1.0)","text":"<ul> <li>Type: Aural</li> <li>Focus: Spectral Artifacts</li> <li>Description: PSA-Net focuses on spectral analysis to detect discrepancies in voice patterns and harmonics, useful in identifying audio deepfakes.</li> </ul>"},{"location":"models/#spot-net-v10","title":"Spot-Net (v1.0)","text":"<ul> <li>Type: Aural</li> <li>Focus: Temporal Artifacts</li> <li>Description: Spot-Net examines voice continuity and timing to detect breaks, delays, or unnatural speech patterns introduced by tampering or generation models.</li> </ul>"},{"location":"models/#model-selection","title":"Model Selection","text":"<p>The appropriate model(s) are automatically selected based on the uploaded media type: - Video \u2192 Audiovisual + Visual + Audio Models - Image \u2192 Visual Models only - Audio \u2192 Audio Models only</p> <p>Each model contributes its prediction and confidence score to the final decision.</p>"},{"location":"security/","title":"Security &amp; Privacy","text":"<p>At ProbeTruth, safeguarding your data and privacy is at the core of our platform. We are committed to providing a secure, trustworthy environment for detecting deepfakes and protecting digital identity.</p>"},{"location":"security/#data-handling","title":"Data Handling","text":"<ul> <li>End-to-End Encryption: All media uploads and API requests are encrypted using HTTPS (TLS 1.2+).</li> <li>Temporary Storage: Uploaded media files are stored only for the duration required to complete analysis.</li> <li>Automatic Deletion: Media files are automatically deleted after inspection and report generation, unless retention is explicitly enabled by the user.</li> </ul>"},{"location":"security/#model-isolation","title":"Model Isolation","text":"<ul> <li>Each AI detection model runs in a sandboxed environment to prevent cross-contamination and ensure privacy.</li> <li>No raw media data is shared with external systems or third-party services.</li> </ul>"},{"location":"security/#audit-compliance","title":"Audit &amp; Compliance","text":"<ul> <li>ProbeTruth maintains internal audit logs for critical API events and model decisions.</li> <li>We adhere to data protection standards aligned with GDPR and CCPA requirements.</li> </ul>"},{"location":"security/#api-security","title":"API Security","text":"<ul> <li>API Keys: All endpoints require authentication via secure API keys.</li> <li>Rate Limiting: To prevent abuse, API usage is rate-limited and monitored.</li> <li>Token Expiry: Temporary access tokens (when used) expire automatically to reduce risk.</li> </ul>"},{"location":"security/#integrity-protection","title":"Integrity Protection","text":"<ul> <li>Hash Verification: Media file integrity is checked using SHA-256 hash comparison during upload.</li> <li>Tamper Detection: We monitor anomalies in model execution that may indicate malicious inputs.</li> </ul>"},{"location":"security/#questions","title":"Questions?","text":"<p>For inquiries related to security or privacy compliance, contact our security team at:</p> <p>security@probetruth.ai</p>"},{"location":"api/api_reference/","title":"API Reference","text":"<p>Welcome to the ProbeTruth API Reference. This section provides an organized overview of all the available endpoints used to interact with the ProbeTruth deepfake detection system.</p> <p>All endpoints below are prefixed with this base URL.</p>"},{"location":"api/api_reference/#authentication","title":"Authentication","text":"<p>All API requests must include a valid API key in the header:</p> <p>Refer to the Authentication Guide for full details.</p>"},{"location":"api/api_reference/#upload-media","title":"Upload Media","text":"<p>Upload a video, audio, or image file for analysis.</p> <p>Endpoint: <code>POST /v1/media</code> View full documentation \u2192</p>"},{"location":"api/api_reference/#inspect-media","title":"Inspect Media","text":"<p>Trigger forensic inspection on previously uploaded media.</p> <p>Endpoint: <code>POST /v1/inspection</code> View full documentation \u2192</p>"},{"location":"api/api_reference/#generate-forensic-report","title":"Generate Forensic Report","text":"<p>Retrieve a detailed report after inspection is completed.</p> <p>Endpoint: <code>POST /v1/reports</code> View full documentation \u2192</p>"},{"location":"api/authentication/","title":"Authentication","text":""},{"location":"api/authentication/#api-authentication","title":"API Authentication","text":"<p>All requests to the ProbeTruth API must be authenticated using secure, token-based authentication provided by Amazon Cognito. This ensures robust, scalable access control to our deepfake detection services.</p> <p>We no longer support static API keys for production access due to security and scalability limitations.</p>"},{"location":"api/authentication/#overview-of-authentication-flow","title":"Overview of Authentication Flow","text":"<ol> <li>Clients authenticate using Amazon Cognito and obtain a JWT access token.</li> <li>Clients include this token in the <code>Authorization</code> header when calling any protected API endpoint.</li> <li>API Gateway validates the token before forwarding the request to the backend (e.g., Lambda, ECS, or SageMaker model).</li> </ol>"},{"location":"api/authentication/#getting-access","title":"Getting Access","text":"<p>To gain access to the ProbeTruth API:</p> <ol> <li>Contact us at demo@probetruth.ai to request API access.</li> <li>We\u2019ll provision access to a Cognito User Pool and send you the necessary credentials (Client ID, Pool ID, Region).</li> <li>Additionally, your IP address will be whitelisted for enhanced security.</li> <li>You can authenticate via:<ul> <li>Hosted UI (Login page hosted by Cognito)</li> <li>Directly using SDKs like AWS Amplify or Amazon Cognito Identity SDK.</li> </ul> </li> </ol>"},{"location":"api/authentication/#token-based-authentication","title":"Token-Based Authentication","text":"<p>Once authenticated, your client will receive a JWT access token from Cognito. These tokens are valid for 24 hours.</p> <p>Include this token in the <code>Authorization</code> header of all API requests:</p> <p>Authorization: Bearer <code>&lt;your_jwt_token_here&gt;</code></p> <p>The token is automatically validated by our API Gateway Authorizer before any request is forwarded to the inference engine.</p>"},{"location":"api/authentication/#example-python-jwt","title":"Example (Python + JWT)","text":"<pre><code>import requests\n\nJWT_TOKEN = 'your_jwt_access_token_here'\nAPI_URL = 'https://api.probetruth.ai/v1/inspection/{upload_id}'\n\nheaders = {\n'Authorization': f'Bearer {JWT_TOKEN}'\n}\n\nresponse = requests.get(API_URL, headers=headers)\n\nif response.ok:\nprint(\"Success:\", response.json())\nelse:\nprint(\"Error:\", response.status_code, response.text)\n</code></pre>"},{"location":"api/authentication/#authenticating-with-cognito","title":"Authenticating with Cognito","text":"<p>To get a token, you can authenticate with Cognito using:</p>"},{"location":"api/authentication/#option-a-hosted-ui-oauth2-login","title":"Option A: Hosted UI (OAuth2 Login)","text":"<p>You\u2019ll be redirected to a Cognito-hosted login page. Upon login, Cognito redirects you back to your app with a token.</p>"},{"location":"api/authentication/#option-b-programmatic-login-for-cli-or-backend-clients","title":"Option B: Programmatic Login (for CLI or backend clients)","text":"<p>You can use the AWS Cognito Identity SDK:</p> <pre><code>import boto3\n\nclient = boto3.client('cognito-idp', region_name='your-region')\n\nresponse = client.initiate_auth(\nClientId='your_cognito_client_id',\nAuthFlow='USER_PASSWORD_AUTH',\nAuthParameters={\n'USERNAME': 'your_username',\n'PASSWORD': 'your_password'\n}\n)\n\njwt_token = response['AuthenticationResult']['AccessToken']\n</code></pre>"},{"location":"api/authentication/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Never expose your token in frontend JavaScript or public repositories.</li> <li>Rotate credentials periodically.</li> <li>Use third-party tools like SecurityScorecard to regularly assess the security posture of your application.</li> </ul>"},{"location":"api/authentication/#coming-soon","title":"Coming Soon","text":"<ul> <li>OAuth2 scope-based permission control (e.g., <code>read:reports</code>, <code>submit:job</code>)</li> <li>Multi-tenant access via Cognito User Groups and Roles</li> <li>Temporary session tokens via AWS STS for advanced clients</li> </ul>"},{"location":"api/generate_report/","title":"Generate Forensic Report","text":"<p>After media inspection is complete (see Media Inspection Endpoints), a detailed forensic report can be generated. This report includes classification results (e.g., real, fake) along with the model\u2019s confidence score, and can be downloaded as a PDF or JSON for documentation purposes.</p>"},{"location":"api/generate_report/#endpoint","title":"Endpoint","text":"<p>POST https://api.probetruth.ai/v1/reports</p>"},{"location":"api/generate_report/#authentication","title":"Authentication","text":"<p>This endpoint requires a valid API key. Include it in the <code>Authorization</code> header. Tokens are valid for 24 hours.:</p> <p><code>Authorization: Bearer YOUR_API_KEY</code></p> <p>API is accessible from whitelisted IPs. Ensure your IP is registered with ProbeTruth. SecurityScorecard tools are used to validate service security.</p>"},{"location":"api/generate_report/#headers","title":"Headers","text":"Key Value <code>Authorization</code> <code>Bearer &lt;your_jwt_token_here&gt;</code> <code>Content-Type</code> <code>application/json</code> <code>Accept</code> <code>application/pdf</code> or <code>application/json</code> <p>Note: The media type (PDF/JSON) is inferred from the Accept header. No need to specify this in the body.</p>"},{"location":"api/generate_report/#request-body","title":"Request Body","text":"Field Type Required Description <code>media_id</code> <code>string</code> Yes The unique ID of the media file to generate the report for. <code>case_id</code> <code>string</code> Yes Case number to associate the report with legal tracking."},{"location":"api/generate_report/#example-request","title":"Example Request","text":"<pre><code>curl -X POST https://api.probetruth.ai/v1/reports \\\n  -H \"Authorization: Bearer &lt;your_jwt_token_here&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Accept: application/pdf\" \\\n  -d '{\n        \"media_id\": \"b91c0fe3-523d-4d3a-9e0e-17cc81c513ab\",\n        \"case_id\": \"CASE-2025-0001\"\n      }'\n</code></pre>"},{"location":"api/generate_report/#response","title":"Response","text":""},{"location":"api/generate_report/#success-pdf-report-200-ok-returns-a-binary-stream-of-the-pdf","title":"Success: PDF Report (200 OK) returns a binary stream of the PDF:","text":"<pre><code>%PDF-1.7\n1 0 obj\n...binary PDF data...\n%%EOF\n</code></pre> <p>The PDF file will be directly streamed in the response body with the <code>Content-Type: application/pdf</code> header.</p>"},{"location":"api/generate_report/#success-json-report-200-ok-returns-the-url-of-the-json","title":"Success: JSON Report (200 OK) returns the URL of the JSON:","text":"<pre><code>{\n  \"media_id\": \"b91c0fe3-523d-4d3a-9e0e-17cc81c513ab\",\n  \"case_id\": \"CASE-2025-0001\",\n  \"status\": \"suspicious\",\n  \"confidence\": 0.78,\n  \"report_url\": \"https://cdn.probetruth.ai/reports/CASE-2025-0001.json\"\n}\n</code></pre> <p>Error Responses</p> HTTP Status Code Response Body (JSON) Description <code>401 Unauthorized</code> <code>json { \"error\": \"Unauthorized\", \"message\": \"Invalid or missing token.\" }</code> Authentication failed. Ensure a valid JWT token is provided. <code>400 Bad Request</code> <code>json { \"error\": \"Bad Request\", \"message\": \"The 'media_id' field is required.\" }</code> The <code>media_id</code> field is missing in the request body. <code>404 Not Found</code> <code>json { \"error\": \"Not Found\", \"message\": \"Media with ID 'invalid-id' not found or analysis not completed.\" }</code> The specified <code>media_id</code> does not exist or the analysis for it is not yet complete. <code>500 Internal Server Error</code> <code>json { \"error\": \"Internal Server Error\", \"message\": \"Failed to generate report.\" }</code> An unexpected error occurred on the server while generating the report."},{"location":"api/generate_report/#request-example-python","title":"Request Example (Python)","text":"<pre><code>import requests\n\ntoken = 'your_jwt_token_here'\nmedia_id = 'b91c0fe3-523d-4d3a-9e0e-17cc81c513ab'\ncase_id = 'CASE-2025-0001'\n\nheaders = {\n    'Authorization': f'Bearer {token}',\n    'Content-Type': 'application/json',\n    'Accept': 'application/pdf'\n}\n\ndata = {\n    'media_id': media_id,\n    'case_id': case_id\n}\n\nresponse = requests.post('https://api.probetruth.ai/v1/reports', headers=headers, json=data, stream=True)\n\nif response.status_code == 200:\n    with open(f'report_{case_id}.pdf', 'wb') as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n    print(\"Report downloaded successfully.\")\nelse:\n    print(f\"Failed to generate report: {response.status_code} - {response.text}\")\n</code></pre>"},{"location":"api/generate_report/#developer-notes","title":"Developer Notes","text":"<ul> <li>Media type (PDF/JSON) is handled via the <code>Accept</code> header.</li> <li>IP whitelisting is enforced at the firewall level.</li> <li>All uploaded files are deleted after inspection; only SHA256 hashes and forensic reports are stored.</li> <li><code>status</code> (<code>real</code>, <code>fake</code>) and confidence score are returned in the report.</li> <li>All endpoints are tested with SecurityScorecard for cybersecurity compliance.</li> </ul>"},{"location":"api/inspect_media/","title":"Inspect Media","text":"<p>Once a media file is successfully uploaded via the Upload Media Endpoint, you can initiate a forensic deepfake analysis using the Media Inspection endpoint.</p> <p>We only store the hash of the file and the forensic report. The media file is deleted after inspection.</p> <p>Once a media file is successfully uploaded using the Upload Media Endpoints, you can initiate deepfake analysis by calling the dedicated inspection endpoint for the specific media type and providing the <code>upload_id</code> in the request body.</p> <p>There are separate endpoints to trigger the inspection process based on the type of uploaded media.</p>"},{"location":"api/inspect_media/#1-initiate-media-inspection","title":"1. Initiate Media Inspection","text":"<p>The <code>POST /v1/inspection</code> endpoint triggers the deepfake analysis pipeline for a previously uploaded media.</p>"},{"location":"api/inspect_media/#endpoint","title":"Endpoint","text":"<p><code>POST https://api.probetruth.ai/v1/inspection</code></p>"},{"location":"api/inspect_media/#authentication","title":"Authentication","text":"<p>This endpoint requires a valid API key. Include it in the <code>Authorization</code> header. Tokens are valid for 24 hours.:</p> <p><code>Authorization: Bearer YOUR_API_KEY</code></p> <p>API is accessible from whitelisted IPs. Ensure your IP is registered with ProbeTruth. SecurityScorecard tools are used to validate service security.</p>"},{"location":"api/inspect_media/#request-body","title":"Request Body","text":"Field Type Required Description <code>upload_id</code> string Yes The unique ID of the uploaded media file. <code>case_id</code> string Yes Identifier for report tracking &amp; generation <p>Content-Type: <code>application/json</code></p>"},{"location":"api/inspect_media/#example-request","title":"Example Request","text":"<pre><code>curl -X POST https://api.probetruth.ai/v1/inspection \\\n  -H \"Authorization: Bearer &lt;your_jwt_token_here&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"upload_id\": \"845f9ac7-9a71-4fcb-8e25-2b7234c6e3fc\",\n        \"case_id\": \"CASE-001\"\n      }'\n</code></pre>"},{"location":"api/inspect_media/#example-success-response-inspection-initiated","title":"Example Success Response (Inspection Initiated)","text":"<pre><code>{\n  \"upload_id\": \"845f9ac7-9a71-4fcb-8e25-2b7234c6e3fc\",\n  \"case_id\": \"CASE-001\",\n  \"analysis_status\": \"queued\",\n  \"message\": \"Media inspection initiated.\"\n}\n</code></pre>"},{"location":"api/inspect_media/#missing-upload-id-or-case-id","title":"Missing Upload ID or Case ID","text":"<pre><code>{\n  \"error\": \"Bad Request\",\n  \"message\": \"The 'upload_id' and 'case_id' fields are required.\"\n}\n</code></pre>"},{"location":"api/inspect_media/#invalid-upload-id","title":"Invalid Upload ID","text":"<pre><code>{\n  \"error\": \"Not Found\",\n  \"message\": \"Media with upload ID 'invalid-id' not found.\"\n}\n</code></pre>"},{"location":"api/inspect_media/#unauthorized-token","title":"Unauthorized Token","text":"<pre><code>{\n  \"error\": \"Unauthorized\",\n  \"message\": \"Invalid or missing token.\"\n}\n</code></pre>"},{"location":"api/inspect_media/#incorrect-media-type-auto-detected-internally","title":"Incorrect Media Type (Auto-detected internally)","text":"<pre><code>{\n  \"error\": \"Invalid Request\",\n  \"message\": \"Upload ID 'xyz' does not correspond to a valid media file.\"\n}\n</code></pre>"},{"location":"api/inspect_media/#2-get-media-inspection-status","title":"2. Get Media Inspection Status","text":""},{"location":"api/inspect_media/#endpoint_1","title":"Endpoint","text":"<p><code>GET https://api.probetruth.ai/v1/inspection/{upload_id}</code></p> <p>This returns the current analysis status and the final result if available.</p>"},{"location":"api/inspect_media/#success-response","title":"Success Response","text":"<pre><code>{\n  \"upload_id\": \"845f9ac7-9a71-4fcb-8e25-2b7234c6e3fc\",\n  \"case_id\": \"CASE-001\",\n  \"status\": \"completed\",\n  \"result\": \"fake\",\n  \"confidence\": 0.92,\n  \"hash\": \"SHA256:ae29cbf7d2...\",\n  \"report_available\": true\n}\n</code></pre>"},{"location":"api/inspect_media/#status-values","title":"Status Values","text":"<ul> <li>queued</li> <li>processing</li> <li>completed</li> <li>failed</li> </ul>"},{"location":"api/inspect_media/#security-best-practices","title":"Security &amp; Best Practices","text":"<ul> <li>Tokens are valid for 24 hours  </li> <li>IP whitelisting enforced for access  </li> <li>Files are deleted post-inspection  </li> <li>Only SHA256 file hashes are stored  </li> <li>SecurityScorecard is used periodically to test API security  </li> </ul>"},{"location":"api/models/","title":"Detection Models","text":"<p>ProbeTruth leverages a suite of advanced AI models to detect deepfakes across visual, audio, and audiovisual domains. Each model targets specific forgery cues using state-of-the-art machine learning techniques.</p>"},{"location":"api/models/#audiovisual-model","title":"Audiovisual Model","text":""},{"location":"api/models/#darl-v10","title":"DARL (v1.0)","text":"<ul> <li>Type: Audiovisual</li> <li>Focus: Speech-Lips Synchronization</li> <li>Description: DARL analyzes the temporal alignment between speech audio and corresponding lip movements in video. It flags inconsistencies that are indicative of synthetic tampering or lip-sync manipulation.</li> </ul>"},{"location":"api/models/#visual-models","title":"Visual Models","text":""},{"location":"api/models/#dbag-net-v10","title":"DBaG-Net (v1.0)","text":"<ul> <li>Type: Visual</li> <li>Focus: Facial Geometry</li> <li>Description: DBaG-Net detects abnormalities in facial proportions, landmarks, and geometric consistency that are often introduced by deepfake generation processes.</li> </ul>"},{"location":"api/models/#atten-vit-v10","title":"Atten-ViT (v1.0)","text":"<ul> <li>Type: Visual</li> <li>Focus: Spatial Artifacts</li> <li>Description: Based on Vision Transformers, Atten-ViT captures subtle pixel-level and regional inconsistencies, such as unnatural textures or blending errors in forged images or video frames.</li> </ul>"},{"location":"api/models/#audio-models","title":"Audio Models","text":""},{"location":"api/models/#audio-rrl-v10","title":"Audio-RRL (v1.0)","text":"<ul> <li>Type: Aural</li> <li>Focus: Spectro-temporal Artifacts</li> <li>Description: Audio-RRL identifies temporal inconsistencies and unnatural frequency patterns in audio, which may result from voice synthesis or manipulation techniques.</li> </ul>"},{"location":"api/models/#psa-net-v10","title":"PSA-Net (v1.0)","text":"<ul> <li>Type: Aural</li> <li>Focus: Spectral Artifacts</li> <li>Description: PSA-Net focuses on spectral analysis to detect discrepancies in voice patterns and harmonics, useful in identifying audio deepfakes.</li> </ul>"},{"location":"api/models/#spot-net-v10","title":"Spot-Net (v1.0)","text":"<ul> <li>Type: Aural</li> <li>Focus: Temporal Artifacts</li> <li>Description: Spot-Net examines voice continuity and timing to detect breaks, delays, or unnatural speech patterns introduced by tampering or generation models.</li> </ul>"},{"location":"api/models/#model-selection","title":"Model Selection","text":"<p>The appropriate model(s) are automatically selected based on the uploaded media type: - Video \u2192 Audiovisual + Visual + Audio Models - Image \u2192 Visual Models only - Audio \u2192 Audio Models only</p> <p>Each model contributes its prediction and confidence score to the final decision.</p>"},{"location":"api/upload/","title":"Upload Media","text":"<p>The <code>POST /v1/media</code> endpoint allows you to upload video, audio, or image files for deepfake forensic inspection. This is the first step in the ProbeTruth detection pipeline.</p> <p>You can upload videos, audio, or images for forensic evaluation.</p>"},{"location":"api/upload/#endpoint","title":"Endpoint","text":"<p><code>POST https://api.probetruth.ai/v1/media</code></p>"},{"location":"api/upload/#authentication","title":"Authentication","text":"<p>This endpoint requires a valid API key. Include it in the <code>Authorization</code> header. Tokens are valid for 24 hours.:</p> <p><code>Authorization: Bearer YOUR_API_KEY</code></p> <p>API is accessible from whitelisted IPs. Ensure your IP is registered with ProbeTruth. SecurityScorecard tools are used to validate service security.</p>"},{"location":"api/upload/#supported-media-types","title":"Supported Media Types","text":"<ul> <li>\u2014 Video <code>.mp4</code> <code>.mkv</code> <code>.avi</code> <code>.mov</code> <code>.wmv</code> <code>.flv</code> <code>.webm</code> </li> <li>\u2014 Audio <code>.mp3</code> <code>.wav</code> <code>.aac</code> <code>.flac</code> </li> <li>\u2014 Image <code>.jpg</code> <code>.png</code> <code>.bmp</code> <code>.tiff</code> </li> </ul>"},{"location":"api/upload/#headers","title":"Headers","text":"Key Value Authorization Bearer <code>&lt;your_jwt_token_here&gt;</code> Content-Type multipart/form-data"},{"location":"api/upload/#request-body","title":"Request Body","text":"Field Type Required Description file file Yes The media file to be analyzed filename string No Optional custom name for the upload"},{"location":"api/upload/#example-upload-media","title":"Example: Upload Media","text":"<pre><code>curl -X POST https://api.probetruth.ai/v1/media \\\n  -H \"Authorization: Bearer &lt;your_jwt_token_here&gt;\" \\\n  -F \"file=@/path/to/your/video.mp4\" \\\n</code></pre> <p>Response</p> <pre><code>{\n  \"upload_id\": \"b91c0fe3-523d-4d3a-9e0e-17cc81c513ab\",\n  \"status\": \"uploaded\",\n  \"message\": \"Media successfully uploaded and queued for analysis.\"\n}\n</code></pre>"},{"location":"api/upload/#error-responses","title":"Error Responses","text":"<p>All endpoints return these common error responses:</p> <p>400 Bad Request</p> <pre><code>{\n  \"error\": \"Invalid file type\",\n  \"allowed_types\": [\"mp4\", \"mp3\", ...]\n}\n</code></pre> <p>401 Unauthorized</p> <pre><code>{\n  \"error\": \"Invalid authentication token\"\n}\n</code></pre> <p>413 Payload Too Large</p> <pre><code>{\n  \"error\": \"File size exceeds 500MB limit\"\n}\n</code></pre>"},{"location":"api/upload/#next-step","title":"Next Step","text":"<p>Once uploaded, use the returned <code>upload_id</code> to perform media inspection:</p> <pre><code>POST /v1/inspection\n</code></pre>"},{"location":"api/upload/#developer-notes","title":"Developer Notes","text":"<ul> <li>Use unique filenames to avoid collisions in downstream processing.</li> <li>Media larger than 500MB may fail to upload depending on server-side configuration.</li> <li>Accepted media types are validated on the backend. If you're unsure, validate the file type before uploading.</li> <li>After uploading, you will receive a media_id used in subsequent API calls (inspect, generate report, etc.).</li> </ul>"}]}